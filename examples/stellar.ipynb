{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stellar Graph Analytics\n",
    "## Python Client Walkthrough\n",
    "This notebook is designed to show the functionality of the Stellar Graph Analytics library v0.2.\n",
    "\n",
    "This demo will show the following functionality from the Stellar library:\n",
    "\n",
    "- **Construct A Graph from Relational Data**: Pull in multiple CSV datasets and convert to a graph\n",
    "\n",
    "- **Run Entity Resolution**: Run basic entity resolution on the graph (demo only)\n",
    "\n",
    "- **Predict A Node Attribute**: Run a predictive model to predict an unknown attribute\n",
    "\n",
    "- **Convert the Output to Gephi**: Visualisation can be done by exporting to GraphML\n",
    "\n",
    "Note that this library is simply a prototype, and has limitations:\n",
    "\n",
    "- Small graphs only e.g. < 50,000 nodes\n",
    "\n",
    "- Entity Resolution is limited to the CORA dataset\n",
    "\n",
    "- Only CSV files are supported for the data ingestion\n",
    "\n",
    "The dataset used in this demo is a synthetic dataset derived from the CORA publication network. The data set here describes an artificial database, which contains people with names, addresses and 'risk' level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellar as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Stellar\n",
    "\n",
    "The first step is to connect to the backend, which will be processing the data.\n",
    "\n",
    "The Python client is sending REST commands to the backend to control the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = st.create_session(\"localhost\", 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "In this example, we'll use the CORA-Terror dataset. This dataset has 2 files:\n",
    "- **people.csv**: People with names, addresses, terror-risk level\n",
    "- **links.csv**: Associations between people\n",
    "\n",
    "Note that this is a synthetic dataset and has no connection to the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = pd.read_csv('/tmp/stellar/people.csv')\n",
    "people[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('/tmp/stellar/links.csv')\n",
    "links[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Graph Schema\n",
    "- First we need to define a schema for our graph.\n",
    "\n",
    "- For this we need to define types for our **nodes** (vertices) and **edges** (links). For example, we may want a *Person* type connected to a *Business* type via a *works-for* edge.\n",
    "\n",
    "- On both nodes and edges, you can also add **properties** to hold additional information.\n",
    "\n",
    "- To create a schema, we can use `create_schema`.\n",
    "\n",
    "- To add nodes and edges we use `add_node_type` and `add_edge_type` respectively.\n",
    "\n",
    "In our example graph, we will describe people and their connections. We will describe our node as:\n",
    "- **Person**\n",
    "    - A name property\n",
    "    - An address property\n",
    "    - A risk level property\n",
    "    - A connection (edge) to another Person (**Association**)\n",
    "\n",
    "Note that the schema is arbitrary, you can define any schema you like to fit your relational data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homogeneous network of people and their associations\n",
    "schema = (st.create_schema()\n",
    "     .add_node_type(\n",
    "        name='Person',\n",
    "        attribute_types={\n",
    "            'name': 'string',\n",
    "            'address': 'string',\n",
    "            'risk': 'string'\n",
    "        })\n",
    "     .add_edge_type(\n",
    "        name='Association',\n",
    "        src_type='Person',\n",
    "        dst_type='Person'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect Data to the Graph Schema\n",
    "\n",
    "Now that we have our schema, next we need to let Stellar know which column goes where.\n",
    "\n",
    "To do this we need to create a **Mapping**. This mapping object defines where the schema can find it's data. We use `create_map` our data sources to a part of the schema.\n",
    "\n",
    "For each **node** we need to give Stellar an 'id' column. This will be assigned to each new node.\n",
    "\n",
    "We can also assign columns to properties. Note that the properties must align with the 'id' column in the CSV file.\n",
    "\n",
    "Here we map the **people.csv** file onto the **Person** nodes, and we map the **links.csv** file onto the **Association** edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# First we create a mapping for the Person node. We use create_map\n",
    "# to point to the 'people.csv' dataset. The identifier for the Person\n",
    "# node is specified in the 'column' attribute. This should be a unique\n",
    "# identifier. All other properties can be mapped to columns using the\n",
    "# map_attributes function.\n",
    "#\n",
    "people_map = schema.node['Person'].create_map(\n",
    "    path='people.csv',\n",
    "    column='id',\n",
    "    map_attributes={\n",
    "        'name': 'name',\n",
    "        'address': 'address',\n",
    "        'risk': 'risk'\n",
    "    }\n",
    ")\n",
    "\n",
    "#\n",
    "# We define the person's 'Association' edges using the 'links.csv' file.\n",
    "# For an edge we need to define a source (src) and destination (dst).\n",
    "# This needs to point to columns that contain the Node id's of the src\n",
    "# and dst defined in the schema.\n",
    "#\n",
    "assoc_map = schema.edge['Association'].create_map(\n",
    "    path='links.csv',\n",
    "    src='PERSON1',\n",
    "    dst='PERSON2'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A Graph\n",
    "Now that we have our dataset, our schema, and our mappings defined, we can tell Stellar to create our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ss.ingest(\n",
    "    schema=schema,\n",
    "    mappings=[schema, people_map, assoc_map],\n",
    "    timeout=60,\n",
    "    label='papers'\n",
    ")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've also included a `to_graphml` conversion function. We can use this to view our graph in **Gephi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.to_graphml('/tmp/stellar/graph-ingest.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution\n",
    "\n",
    "A module included in Stellar is the Entity Resolution module. This module will take a graph object, match fields on nodes to determine which nodes may be identical. For example, a person may appear twice in the graph, once with 'Bill J. Johnson' and another time with 'Bill Johnson'. The goal of the Entity Resolution module is to identify potential duplicates by resolving the true entities.\n",
    "\n",
    "This module will return a new graph with **is-same-as** edges added to the graph where the algorithm thinks there may be a duplicate. A confidence score will also be attached to the link as a property.\n",
    "\n",
    "Note that this module is a baseline only, and is configured to work with the cora-terror set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_predicted = ss.predict(\n",
    "    graph=graph,\n",
    "    model=st.model.Node2Vec(),\n",
    "    target_attribute='venue', \n",
    "    node_type='Paper', \n",
    "    attributes_to_ignore=['dataset', 'title', '__id'],\n",
    "    timeout=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_predicted.to_graphml('/home/ubuntu/papers.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction\n",
    "This module uses machine learning to predict missing properties on nodes. Underneath the hood there is a small pipeline that:\n",
    "- Performs a train/test split\n",
    "- Trains a machine learning model\n",
    "- Uses the model to predict missing values\n",
    "\n",
    "The module also allows different models to be chosen. The models available in this demo are the following:\n",
    "\n",
    "- **Node2Vec**: Creates machine learning features describing the structure of the graph\n",
    "\n",
    "- **GCN**: The Graph Convolutional Network model uses deep learning to learn the surrounding structure of the graph\n",
    "\n",
    "To run the module, a `target` attribute needs to be chosen. This will be the attribute that is predicted. You can also use `attributes_to_ignore` to remove attributes from the calculation.\n",
    "\n",
    "This module also allows heterogeneous datasets to be used. This will be performed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_predicted = ss.predict(\n",
    "    graph=graph,\n",
    "    model=st.model.Node2Vec(),\n",
    "    target_attribute='venue', \n",
    "    node_type='Paper', \n",
    "    attributes_to_ignore=['dataset', 'title', '__id'],\n",
    "    timeout=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_predicted.to_graphml('/home/ubuntu/papers.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
